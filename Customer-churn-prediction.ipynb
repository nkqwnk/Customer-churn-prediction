{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование оттока клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном исследовании нашей целью является прогнозирование ухода клиента из банка в ближайшее время. В наличии у нас имеются исторические данные, отражающие поведение клиентов, для каждого из которых известно, перестал ли он вести свои дела в банке.<br>\n",
    "В ходе проведения исследования необходимо будет построить модель со значением *F1*-меры не меньшим 0.59. Кроме того, будем измерять метрику *AUC-ROC*, сравнивая её значение со значением *F1*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва подключим необходимые для дальнейшей работы библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузим набор данных для исследования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    customer_churn = pd.read_csv('Churn.csv')\n",
    "except:\n",
    "    customer_churn = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглядем на общую информацию об имеющихся данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "customer_churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что набор содержит пропущенные значения в столбце Tenure (количество лет, в течение которых клиент работал с банком). Пропущенные значения помешают обучению, поэтому удалим строки, содержащие их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn = customer_churn.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также обучению помешают неинформативные признаки - номер строки, идентификационный номер клиента и его фамилия. Удалим столбцы, содержащие соответствующие данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn = customer_churn.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем обзор первых 5 строк нашего датафрейма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_churn.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что обучению может помешать наличие категориальных и немасштабированных числовых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем прямое кодирование данных (One-Hot Encoding - OHE), чтобы преобразовать категориальные признаки в численные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_ohe = pd.get_dummies(customer_churn, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на целевой и остальные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = customer_churn_ohe['Exited']\n",
    "features = customer_churn_ohe.drop('Exited', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И проведем разбиение (в пропорции 3:1:1) выборки на обучающую, валидационную и тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features.copy(), target.copy(), \n",
    "                                                                              test_size=0.2, random_state=12345)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train.copy(), target_train.copy(), \n",
    "                                                                              test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем размеры получившихся выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки признаков обучения - (5454, 11), целевого признака - (5454,)\n",
      "Размер валидационной выборки признаков обучения - (1818, 11), целевого признака - (1818,)\n",
      "Размер тестовой выборки признаков обучения - (1819, 11), целевого признака - (1819,)\n"
     ]
    }
   ],
   "source": [
    "features_train.shape, target_train.shape\n",
    "print(f'Размер тренировочной выборки признаков обучения - {features_train.shape}, целевого признака - {target_train.shape}')\n",
    "print(f'Размер валидационной выборки признаков обучения - {features_valid.shape}, целевого признака - {target_valid.shape}')\n",
    "print(f'Размер тестовой выборки признаков обучения - {features_test.shape}, целевого признака - {target_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим масштабирование количественных данных, выделив соответствующие признаки в список numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric]) \n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с изучения баланса классов целевого признака - ушел ли клиент из банка ('Exited'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.796062\n",
       "1    0.203938\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_churn['Exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, размер положительного класса почти в 4 раза меньше размера отрицательного, налицо сильный дисбаланс, работу с которым проведем несколько позже. Сейчас же **проведем обучение моделей на несбалансированных данных**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с модели **логистичекой регрессии**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели логистичекой регрессии - 0.3004115226337448\n",
      "Значение AUC-ROC составляет - 0.772597434855259\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(f'На наших данных лучшее значение F1 меры для модели логистичекой регрессии - {f1_score(target_valid, predicted_valid)}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель **решающего дерева**, с помощью цикла подбирая гиперпараметр max_depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели решающего дерева - 0.557427258805513,\n",
      "Гиперпараметр глубины для этой модели равнялся 9\n",
      "Значение AUC-ROC составляет - 0.8062753089765011\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_decision_tree = 0 #Переменная, где будем хранить значение F1 лучшей модели\n",
    "best_depth_decision_tree = 0 #Переменная, где будем хранить глубину лучшей модели\n",
    "best_model_decision_tree = None #Переменная, в которой будем ходить лучшую модель\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    if f1 > best_f1_score_decision_tree:\n",
    "        best_depth_decision_tree = depth\n",
    "        best_f1_score_decision_tree = f1\n",
    "        best_model_decision_tree = model\n",
    "        \n",
    "print(f'На наших данных лучшее значение F1 меры для модели решающего дерева - {best_f1_score_decision_tree},')\n",
    "print(f'Гиперпараметр глубины для этой модели равнялся {best_depth_decision_tree}')\n",
    "\n",
    "probabilities_valid = best_model_decision_tree.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, проведем обучение модели **случайного леса**, где так же с помощью цикла подберем гиперпараметры n_estimators и max_depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели случайного леса - 0.563573883161512\n",
      "Гиперпараметр количества деревьев для этой модели равнялся 100, а гиперпараметр глубины равнялся 20\n",
      "Значение AUC-ROC составляет - 0.8339900495265622\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_random_forest = 0\n",
    "best_est_random_forest = 0\n",
    "best_depth_random_forest = 0\n",
    "best_model_random_forest = None\n",
    "\n",
    "for est in range(10, 111, 10):\n",
    "    for depth in range (1, 26):\n",
    "        model = RandomForestClassifier(n_estimators=est, max_depth=depth, random_state=12345)\n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predicted_valid)\n",
    "        if f1 > best_f1_score_random_forest:\n",
    "            best_f1_score_random_forest = f1\n",
    "            best_est_random_forest = est\n",
    "            best_depth_random_forest = depth\n",
    "            best_model_random_forest = model\n",
    "\n",
    "print(f'На наших данных лучшее значение F1 меры для модели случайного леса - {best_f1_score_random_forest}')\n",
    "print(f'Гиперпараметр количества деревьев для этой модели равнялся {best_est_random_forest}, а гиперпараметр глубины равнялся {best_depth_random_forest}')\n",
    "\n",
    "probabilities_valid = best_model_random_forest.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**По результатам исследования** трех моделей получили следующие значения F1-мер: модель случайного леса - 0.564 (деревьев - 100, глубина - 20), модель решающего дерева - 0.557 (глубина - 9), модель логистической регрессии - 0.3. **Модель случайного леса на данном этапе видится наиболее перспективной.** Также следует отметить явный **дисбаланс классов**, их соотношение практически равняется 1:4. На следующем этапе работы воспользуемся несколькими способами с этим дисбалансом справиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем работу по балансировке положительного и отрицательного классов целевого признака, кроме F-1 меры будем также рассчитывать и метрику AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Взвешивание классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала попробуем устранить дисбаланс с помощью **взвешивания классов** - передачи моделям аргумента class_weight со значением 'balanced'. Будем тестировать те же модели, так же подбирая гиперпараметры: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем взвешивание для **логистической регрессии**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели логистичекой регрессии - 0.49506903353057197\n",
      "Значение AUC-ROC составляет - 0.7747783347634317\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(f'На наших данных лучшее значение F1 меры для модели логистичекой регрессии - {f1_score(target_valid, predicted_valid)}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для **решающего дерева**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели решающего дерева - 0.5555555555555556,\n",
      "Гиперпараметр глубины для этой модели равнялся 7\n",
      "Значение AUC-ROC составляет - 0.6814851194508422\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_decision_tree = 0 \n",
    "best_depth_decision_tree = 0 \n",
    "best_model_decision_tree = None \n",
    "\n",
    "for depth in range(1, 21):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, class_weight='balanced', random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    if f1 > best_f1_score_decision_tree:\n",
    "        best_depth_decision_tree = depth\n",
    "        best_f1_score_decision_tree = f1\n",
    "        best_model_decision_tree = model\n",
    "        \n",
    "print(f'На наших данных лучшее значение F1 меры для модели решающего дерева - {best_f1_score_decision_tree},')\n",
    "print(f'Гиперпараметр глубины для этой модели равнялся {best_depth_decision_tree}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, для **случайного леса**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели случайного леса - 0.6059743954480795\n",
      "Гиперпараметр количества деревьев для этой модели равнялся 90, а гиперпараметр глубины равнялся 10\n",
      "Значение AUC-ROC составляет - 0.8342694832076353\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_random_forest = 0\n",
    "best_est_random_forest = 0\n",
    "best_depth_random_forest = 0\n",
    "best_model_random_forest = None\n",
    "\n",
    "for est in range(10, 111, 10):\n",
    "    for depth in range (1, 26):\n",
    "        model = RandomForestClassifier(n_estimators=est, max_depth=depth, class_weight='balanced', random_state=12345)\n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predicted_valid)\n",
    "        if f1 > best_f1_score_random_forest:\n",
    "            best_f1_score_random_forest = f1\n",
    "            best_est_random_forest = est\n",
    "            best_depth_random_forest = depth\n",
    "            best_model_random_forest = model\n",
    "\n",
    "print(f'На наших данных лучшее значение F1 меры для модели случайного леса - {best_f1_score_random_forest}')\n",
    "print(f'Гиперпараметр количества деревьев для этой модели равнялся {best_est_random_forest}, а гиперпараметр глубины равнялся {best_depth_random_forest}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный способ балансировки позволил несколько увеличить F1-меру для моделей логистической регрессии и случайного леса - были достигнуты результаты в 0.495 (логистическая регрессия) и 0.612 (случайный лес), результат же для модели решающего дерева немного снизился до 0.556. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Увеличение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь воспользуемся методом **увеличения выборки** (upsampling) - скопируем положительные объекты 4 раза (так как их примерно во столько раз меньше, чем отрицательных). Определим функцию upsample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модели на этих выборках. Снова начнем с **логистической регрессии**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели логистичекой регрессии - 0.4956605593056895\n",
      "Значение AUC-ROC составляет - 0.7748272591789732\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(f'На наших данных лучшее значение F1 меры для модели логистичекой регрессии - {f1_score(target_valid, predicted_valid)}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем обучим модель **решающего дерева**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели решающего дерева - 0.5555555555555556,\n",
      "Гиперпараметр глубины для этой модели равнялся 7\n",
      "Значение AUC-ROC составляет - 0.6753037077180147\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_decision_tree = 0 \n",
    "best_depth_decision_tree = 0 \n",
    "best_model_decision_tree = None \n",
    "\n",
    "for depth in range(1, 21):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    if f1 > best_f1_score_decision_tree:\n",
    "        best_depth_decision_tree = depth\n",
    "        best_f1_score_decision_tree = f1\n",
    "        best_model_decision_tree = model\n",
    "        \n",
    "print(f'На наших данных лучшее значение F1 меры для модели решающего дерева - {best_f1_score_decision_tree},')\n",
    "print(f'Гиперпараметр глубины для этой модели равнялся {best_depth_decision_tree}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, обучим модель **случайного леса**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели случайного леса - 0.6055488540410132\n",
      "Гиперпараметр количества деревьев для этой модели равнялся 40, а гиперпараметр глубины равнялся 9\n",
      "Значение AUC-ROC составляет - 0.8360778048743771\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_random_forest = 0\n",
    "best_est_random_forest = 0\n",
    "best_depth_random_forest = 0\n",
    "best_model_random_forest = None\n",
    "\n",
    "for est in range(10, 111, 10):\n",
    "    for depth in range (1, 26):\n",
    "        model = RandomForestClassifier(n_estimators=est, max_depth=depth, random_state=12345)\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predicted_valid)\n",
    "        if f1 > best_f1_score_random_forest:\n",
    "            best_f1_score_random_forest = f1\n",
    "            best_est_random_forest = est\n",
    "            best_depth_random_forest = depth\n",
    "            best_model_random_forest = model\n",
    "\n",
    "print(f'На наших данных лучшее значение F1 меры для модели случайного леса - {best_f1_score_random_forest}')\n",
    "print(f'Гиперпараметр количества деревьев для этой модели равнялся {best_est_random_forest}, а гиперпараметр глубины равнялся {best_depth_random_forest}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот способ балансировки классов целевого признака так же показал определенные результаты - искомая мера для логистической регрессии слегка выросла до 0.496, для модели решающего дерева она осталась на уровне 0.556, а для случайного леса несколько снизилась до 0.606. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Уменьшение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последним из рассматриваемых нами способов балансировки классов будет **уменьшение выборки** (downsampling). Схожим образом определим функцию downsample, а число отрицательных сократим в 4 раза (получим 0.25 от их изначального количества):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем обучение с **логистической регрессии**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели логистичекой регрессии - 0.5\n",
      "Значение AUC-ROC составляет - 0.7754858570804919\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',random_state=12345)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(f'На наших данных лучшее значение F1 меры для модели логистичекой регрессии - {f1_score(target_valid, predicted_valid)}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь займемся обучением модели **решающего дерева**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели решающего дерева - 0.553191489361702,\n",
      "Гиперпараметр глубины для этой модели равнялся 5\n",
      "Значение AUC-ROC составляет - 0.6903253849975162\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_decision_tree = 0 \n",
    "best_depth_decision_tree = 0 \n",
    "best_model_decision_tree = None \n",
    "\n",
    "for depth in range(1, 21):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model.fit(features_downsampled, target_downsampled)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    if f1 > best_f1_score_decision_tree:\n",
    "        best_depth_decision_tree = depth\n",
    "        best_f1_score_decision_tree = f1\n",
    "        best_model_decision_tree = model\n",
    "        \n",
    "print(f'На наших данных лучшее значение F1 меры для модели решающего дерева - {best_f1_score_decision_tree},')\n",
    "print(f'Гиперпараметр глубины для этой модели равнялся {best_depth_decision_tree}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, проведем обучение для модели **случайного леса**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На наших данных лучшее значение F1 меры для модели случайного леса - 0.5920177383592018\n",
      "Гиперпараметр количества деревьев для этой модели равнялся 80, а гиперпараметр глубины равнялся 9\n",
      "Значение AUC-ROC составляет - 0.8355010612834756\n"
     ]
    }
   ],
   "source": [
    "best_f1_score_random_forest = 0\n",
    "best_est_random_forest = 0\n",
    "best_depth_random_forest = 0\n",
    "best_model_random_forest = None\n",
    "\n",
    "for est in range(10, 111, 10):\n",
    "    for depth in range (1, 26):\n",
    "        model = RandomForestClassifier(n_estimators=est, max_depth=depth, random_state=12345)\n",
    "        model.fit(features_downsampled, target_downsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predicted_valid)\n",
    "        if f1 > best_f1_score_random_forest:\n",
    "            best_f1_score_random_forest = f1\n",
    "            best_est_random_forest = est\n",
    "            best_depth_random_forest = depth\n",
    "            best_model_random_forest = model\n",
    "\n",
    "print(f'На наших данных лучшее значение F1 меры для модели случайного леса - {best_f1_score_random_forest}')\n",
    "print(f'Гиперпараметр количества деревьев для этой модели равнялся {best_est_random_forest}, а гиперпараметр глубины равнялся {best_depth_random_forest}')\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_valid, probabilities_one_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова отметим рост F1-меры для модели логистической регрессии, на этот раз она составила 0.5, мера для решающего дерева несколько снизилась до 0.553, снизилась она и для случайного леса - до 0.595."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Итоги балансировки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате проведенной работы по ликвидации дисбаланса положительного и отрицательного классов пришли к следующим наилучшим значениям F1-меры для каждой из моделей:\n",
    "1. Логистическая регрессия - 0.5 с помощью уменьшения выборки, при метрике AUC-ROC равной 0.775.\n",
    "2. Решающее дерево - 0.556 с помощью взвешивания и увеличения выборки (что меньше меры для несбалансированной выборки - 0.557), при метрике AUC-ROC равной 0.675.\n",
    "3. Случайный лес - 0.612 с помощью взвешивания, при метрике AUC-ROC равной 0.84.\n",
    "Как видим, **лучший результат показала модель случайного леса, обученная на взвешенных данных**, тестирование которой мы и проведем на следующем шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'> ✔️ Отлично, борьба с дисбалансом дала положительные результаты!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заканчивая исследование, проверим качество работы нашей модели случайного леса, обученной на взвешенных данных. Гиперпараметры, позволившие нам достичь максимального результата на валидационной выборке - n_estimators=90, max_depth=10. Качество оценим с помощью меры F1 и AUC-ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1 составляет - 0.5986206896551723\n",
      "Значение AUC-ROC составляет - 0.8566134006167648\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=90, max_depth=10, class_weight='balanced', random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_test = model.predict(features_test)\n",
    "print(f'Значение F1 составляет - {f1_score(target_test, predicted_test)}')\n",
    "\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print(f'Значение AUC-ROC составляет - {roc_auc_score(target_test, probabilities_one_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, получив значения 0.601 для F1-меры и 0.857 для AUC-ROC, будем считать проведенное исследование успешным, так как был преодолен требуемый порог в 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы над исследованием данных о поведении клиентов Бета-банка мы преследовали цель научиться предсказывать, уйдет ли тот или иной клиент из него. Для этого была проведения подготовка данных - мы избавились от лишних признаков у объектов выборки, провели кодирование категориальных признаков и масштабирование количественных. Затем мы осуществили первичное обучение моделей, заметив однако, что классы целевого признака (положительный и отрицательный) не являются сбалансированными. После такого \"сырого\" обучения мы воспользовались некоторыми способами от этого дисбаланса избавиться (взвешенное обучение, увеличение и уменьшение выборки), параллельно обучая модели и вычисляя для них F1-меры и метрику AUC-ROC. В итоге пришли к заключению о том, что наилучшей по этим метрикам моделью для предсказания ухода клиента из банка была модель случайного леса с 90 деревьями и глубиной 10, обученная на взвешенных данных. Заключение это подтвердилось на последнем этапе исследования - предсказания с помощью данной модели на тестовых данных. Было успешно достигнуто значение F1-меры в 0.601, что превышает требуемое значение (0.59)."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1541,
    "start_time": "2022-12-31T04:59:21.120Z"
   },
   {
    "duration": 116,
    "start_time": "2022-12-31T04:59:22.663Z"
   },
   {
    "duration": 13,
    "start_time": "2022-12-31T04:59:50.750Z"
   },
   {
    "duration": 8,
    "start_time": "2022-12-31T04:59:59.700Z"
   },
   {
    "duration": 4,
    "start_time": "2022-12-31T05:00:25.150Z"
   },
   {
    "duration": 15,
    "start_time": "2022-12-31T05:00:40.656Z"
   },
   {
    "duration": 10,
    "start_time": "2022-12-31T05:00:49.841Z"
   },
   {
    "duration": 5,
    "start_time": "2022-12-31T05:02:30.576Z"
   },
   {
    "duration": 8,
    "start_time": "2022-12-31T05:02:50.637Z"
   },
   {
    "duration": 15,
    "start_time": "2022-12-31T05:03:38.274Z"
   },
   {
    "duration": 23,
    "start_time": "2022-12-31T05:03:53.393Z"
   },
   {
    "duration": 5,
    "start_time": "2022-12-31T05:04:27.517Z"
   },
   {
    "duration": 21,
    "start_time": "2022-12-31T05:06:03.589Z"
   },
   {
    "duration": 427,
    "start_time": "2022-12-31T05:09:18.668Z"
   },
   {
    "duration": 80315,
    "start_time": "2022-12-31T05:10:21.158Z"
   },
   {
    "duration": 32,
    "start_time": "2022-12-31T05:12:12.451Z"
   },
   {
    "duration": 434,
    "start_time": "2022-12-31T05:12:18.655Z"
   },
   {
    "duration": 78120,
    "start_time": "2022-12-31T05:12:22.161Z"
   },
   {
    "duration": 11,
    "start_time": "2022-12-31T05:16:04.362Z"
   },
   {
    "duration": 29,
    "start_time": "2022-12-31T05:16:35.503Z"
   },
   {
    "duration": 477,
    "start_time": "2022-12-31T05:16:47.213Z"
   },
   {
    "duration": 107196,
    "start_time": "2022-12-31T05:16:48.077Z"
   },
   {
    "duration": 11,
    "start_time": "2022-12-31T05:18:35.275Z"
   },
   {
    "duration": 40,
    "start_time": "2022-12-31T05:18:35.288Z"
   },
   {
    "duration": 293,
    "start_time": "2022-12-31T05:18:35.421Z"
   },
   {
    "duration": 45344,
    "start_time": "2022-12-31T05:18:35.716Z"
   },
   {
    "duration": 483,
    "start_time": "2022-12-31T05:21:00.454Z"
   },
   {
    "duration": 44,
    "start_time": "2023-01-02T10:29:09.308Z"
   },
   {
    "duration": 1651,
    "start_time": "2023-01-02T10:29:14.922Z"
   },
   {
    "duration": 201,
    "start_time": "2023-01-02T10:29:16.575Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T10:29:16.778Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T10:29:16.793Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T10:29:16.802Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T10:29:16.808Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-02T10:29:16.825Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T10:29:16.837Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T10:29:16.843Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-02T10:30:11.515Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T10:30:21.589Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T10:30:30.584Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T10:32:44.212Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T10:35:02.563Z"
   },
   {
    "duration": 90,
    "start_time": "2023-01-02T10:35:02.569Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T10:35:02.660Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T10:35:02.675Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T10:35:02.685Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-02T10:35:02.691Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T10:35:02.713Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-02T10:35:02.727Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T10:35:02.737Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T10:35:02.747Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-02T10:35:37.579Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:06:11.542Z"
   },
   {
    "duration": 99,
    "start_time": "2023-01-02T11:06:11.549Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-02T11:06:11.649Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T11:06:11.665Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-02T11:06:11.676Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T11:06:11.684Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-02T11:06:11.701Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T11:06:11.724Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T11:06:11.730Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-02T11:06:11.744Z"
   },
   {
    "duration": 26,
    "start_time": "2023-01-02T11:06:16.526Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-02T11:06:24.480Z"
   },
   {
    "duration": 77,
    "start_time": "2023-01-02T11:06:24.486Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T11:06:24.565Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T11:06:24.580Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:06:24.592Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-02T11:06:24.598Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-02T11:06:24.615Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:06:24.631Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T11:06:24.637Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T11:06:24.647Z"
   },
   {
    "duration": 25,
    "start_time": "2023-01-02T11:06:24.654Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T11:07:22.861Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:07:31.276Z"
   },
   {
    "duration": 91,
    "start_time": "2023-01-02T11:07:31.287Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-02T11:07:31.379Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-02T11:07:31.392Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T11:07:31.405Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-02T11:07:31.414Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-02T11:07:31.429Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T11:07:31.446Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-02T11:07:31.455Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-02T11:07:31.476Z"
   },
   {
    "duration": 47,
    "start_time": "2023-01-02T11:07:31.485Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:11:42.556Z"
   },
   {
    "duration": 77,
    "start_time": "2023-01-02T11:11:42.562Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-02T11:11:42.640Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-02T11:11:42.652Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-02T11:11:42.663Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T11:11:42.668Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T11:11:42.682Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:11:42.696Z"
   },
   {
    "duration": 27,
    "start_time": "2023-01-02T11:11:42.701Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-02T11:11:42.730Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-02T11:11:42.737Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-02T11:11:54.388Z"
   },
   {
    "duration": 78,
    "start_time": "2023-01-02T11:11:54.394Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-02T11:11:54.474Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-02T11:11:54.486Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-02T11:11:54.496Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-02T11:11:54.507Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-02T11:11:54.526Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:11:54.541Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-02T11:11:54.547Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:11:54.558Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-02T11:11:54.564Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-02T11:13:10.875Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-02T11:13:25.308Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-02T11:13:27.651Z"
   },
   {
    "duration": 82,
    "start_time": "2023-01-02T11:14:27.741Z"
   },
   {
    "duration": 401,
    "start_time": "2023-01-02T11:16:22.911Z"
   },
   {
    "duration": 34686,
    "start_time": "2023-01-02T11:17:06.152Z"
   },
   {
    "duration": 85026,
    "start_time": "2023-01-02T11:17:54.059Z"
   },
   {
    "duration": 481,
    "start_time": "2023-01-02T11:21:46.330Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-02T11:23:00.186Z"
   },
   {
    "duration": 99,
    "start_time": "2023-01-02T11:23:00.212Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-02T11:23:00.312Z"
   },
   {
    "duration": 28,
    "start_time": "2023-01-02T11:23:00.329Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-02T11:23:00.360Z"
   },
   {
    "duration": 38,
    "start_time": "2023-01-02T11:23:00.379Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-02T11:23:00.418Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-02T11:23:00.444Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-02T11:23:00.457Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-02T11:23:00.469Z"
   },
   {
    "duration": 36,
    "start_time": "2023-01-02T11:23:00.484Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-02T11:23:00.522Z"
   },
   {
    "duration": 94,
    "start_time": "2023-01-02T11:23:00.530Z"
   },
   {
    "duration": 518,
    "start_time": "2023-01-02T11:23:00.626Z"
   },
   {
    "duration": 83506,
    "start_time": "2023-01-02T11:23:01.145Z"
   },
   {
    "duration": 72,
    "start_time": "2023-01-02T11:24:24.653Z"
   },
   {
    "duration": 510,
    "start_time": "2023-01-02T11:24:24.727Z"
   },
   {
    "duration": 82009,
    "start_time": "2023-01-02T11:24:25.239Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-02T11:25:47.249Z"
   },
   {
    "duration": 68,
    "start_time": "2023-01-02T11:25:47.262Z"
   },
   {
    "duration": 674,
    "start_time": "2023-01-02T11:25:47.331Z"
   },
   {
    "duration": 111620,
    "start_time": "2023-01-02T11:25:48.007Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-02T11:27:39.629Z"
   },
   {
    "duration": 79,
    "start_time": "2023-01-02T11:27:39.643Z"
   },
   {
    "duration": 313,
    "start_time": "2023-01-02T11:27:39.724Z"
   },
   {
    "duration": 48439,
    "start_time": "2023-01-02T11:27:40.039Z"
   },
   {
    "duration": 502,
    "start_time": "2023-01-02T11:28:28.480Z"
   },
   {
    "duration": 1640,
    "start_time": "2023-01-03T06:17:19.360Z"
   },
   {
    "duration": 114,
    "start_time": "2023-01-03T06:17:21.002Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-03T06:17:21.118Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-03T06:17:21.144Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-03T06:17:21.154Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-03T06:17:21.160Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-03T06:17:21.180Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-03T06:17:21.191Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-03T06:17:21.215Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-03T06:17:21.241Z"
   },
   {
    "duration": 32,
    "start_time": "2023-01-03T06:17:21.251Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "273px",
    "left": "10px",
    "top": "150px",
    "width": "180px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
